{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Домашняя работа 2\n Изучение GCN, GraphSAGE, GAT, GIN — на задачах \"node classification\" и \"link prediction\"\n\nавтор: `Алексеева Валентина`\n\n\nВ этой домашней работе вам предстоит:\n\n- освоить и углубить понимание нескольких графовых нейросетевых архитектур (GCN, GraphSAGE, GAT, GIN)\n-  применить их к задачам классификации узлов и предсказания рёбер\n- исследовать влияние глубины, скрытой размерности, оптимизации GNN на качество обучения\n- построить сравнительные эксперименты и сделать собственные выводы о преимуществах разных подходов","metadata":{"id":"lUayZDwiYprB"}},{"cell_type":"code","source":"# !pip install torch-geometric -q","metadata":{"id":"WmYj9e7tZmIn","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:21:06.741611Z","iopub.execute_input":"2025-12-07T11:21:06.741870Z","iopub.status.idle":"2025-12-07T11:21:15.542543Z","shell.execute_reply.started":"2025-12-07T11:21:06.741850Z","shell.execute_reply":"2025-12-07T11:21:15.541252Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.nn import GCNConv, GINConv, SAGEConv\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch_geometric.utils import to_networkx\nfrom torch_geometric.transforms import RandomLinkSplit\nfrom torch_geometric.utils import dropout_edge\nfrom torch_geometric.nn import SAGEConv, GATv2Conv\nimport networkx as nx\n\nimport torch.nn as nn\nimport pandas as pd\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"3EhgjBtMZqGx","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:21:15.544782Z","iopub.execute_input":"2025-12-07T11:21:15.545075Z","iopub.status.idle":"2025-12-07T11:21:35.861172Z","shell.execute_reply.started":"2025-12-07T11:21:15.545045Z","shell.execute_reply":"2025-12-07T11:21:35.859981Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Загрузка и визуализация данных\n\nДатасет: Cora - Граф научных цитирований","metadata":{"id":"PhlqXN8lZTl5"}},{"cell_type":"code","source":"dataset = Planetoid(root='/tmp/Cora', name='Cora')\ndata = dataset[0]\nprint(data)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYmTSssoZZaV","outputId":"4750d4d3-37ce-4dad-abe9-071e5c2eec44","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:21:35.862168Z","iopub.execute_input":"2025-12-07T11:21:35.862698Z","iopub.status.idle":"2025-12-07T11:21:39.831975Z","shell.execute_reply.started":"2025-12-07T11:21:35.862673Z","shell.execute_reply":"2025-12-07T11:21:39.830918Z"}},"outputs":[{"name":"stderr","text":"Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n","output_type":"stream"},{"name":"stderr","text":"Done!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Часть 1. Node Classification\n\n### 1.1 Реализация расширенного GCN\n\nСоздайте GCN-модель с:\n\n- тремя слоями GCNConv,\n- Dropout после второго слоя,\n- активацией ReLU в скрытых слоях.\n\n**Вопросы:**\n\n- Улучшилось ли качество на Cora в сравнении с результатом, который был получен на практике?\n- Как изменилась динамика сходимости?\n- Наблюдается ли переобучение?","metadata":{"id":"CYw090lRaEQa"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\ndata = data.to(device)\n\ndef train_node(model, data, optimizer):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n@torch.no_grad()\ndef eval_node(model, data):\n    model.eval()\n    logits = model(data.x, data.edge_index)\n    pred = logits.argmax(dim=1)\n\n    accs = []\n    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n        # mask.sum() — число объектов в маске\n        acc = (pred[mask] == data.y[mask]).sum().item() / int(mask.sum())\n        accs.append(acc)\n    return accs  # [train_acc, val_acc, test_acc]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:22:23.265855Z","iopub.execute_input":"2025-12-07T11:22:23.266182Z","iopub.status.idle":"2025-12-07T11:22:23.275688Z","shell.execute_reply.started":"2025-12-07T11:22:23.266158Z","shell.execute_reply":"2025-12-07T11:22:23.274714Z"}},"outputs":[{"name":"stdout","text":"Device: cpu\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# TODO\nclass GCN3(torch.nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.conv3 = GCNConv(hidden_dim, out_dim)\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        # первый слой\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n\n        # второй слой\n        x = self.conv2(x, edge_index)\n        x = F.relu(x)\n\n        # Dropout после второго скрытого слоя\n        x = F.dropout(x, p=self.dropout, training=self.training)\n\n        # выходной слой (логиты классов)\n        x = self.conv3(x, edge_index)\n        return x\n\n\nhidden_dim = 64\ndropout = 0.5\nepochs = 200\n\nmodel_gcn3 = GCN3(\n    in_dim=data.num_features,\n    hidden_dim=hidden_dim,\n    out_dim=dataset.num_classes,\n    dropout=dropout\n).to(device)\n\noptimizer = torch.optim.Adam(\n    model_gcn3.parameters(),\n    lr=0.01,\n    weight_decay=5e-4\n)\n\ntrain_losses = []\ntrain_accs = []\nval_accs = []\ntest_accs = []\n\nfor epoch in range(1, epochs + 1):\n    loss = train_node(model_gcn3, data, optimizer)\n    train_acc, val_acc, test_acc = eval_node(model_gcn3, data)\n\n    train_losses.append(loss)\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n    test_accs.append(test_acc)\n\n    if epoch % 20 == 0 or epoch == 1:\n        print(\n            f\"Epoch {epoch:03d} | \"\n            f\"Loss: {loss:.4f} | \"\n            f\"Train: {train_acc:.3f} | \"\n            f\"Val: {val_acc:.3f} | \"\n            f\"Test: {test_acc:.3f}\"\n        )","metadata":{"id":"wWaxhLRBckhZ","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:22:32.747610Z","iopub.execute_input":"2025-12-07T11:22:32.748415Z","iopub.status.idle":"2025-12-07T11:22:40.172794Z","shell.execute_reply.started":"2025-12-07T11:22:32.748389Z","shell.execute_reply":"2025-12-07T11:22:40.171861Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 1.9541 | Train: 0.500 | Val: 0.258 | Test: 0.280\nEpoch 020 | Loss: 0.0108 | Train: 1.000 | Val: 0.768 | Test: 0.774\nEpoch 040 | Loss: 0.0023 | Train: 1.000 | Val: 0.772 | Test: 0.795\nEpoch 060 | Loss: 0.0044 | Train: 1.000 | Val: 0.764 | Test: 0.785\nEpoch 080 | Loss: 0.0045 | Train: 1.000 | Val: 0.772 | Test: 0.807\nEpoch 100 | Loss: 0.0065 | Train: 1.000 | Val: 0.774 | Test: 0.811\nEpoch 120 | Loss: 0.0058 | Train: 1.000 | Val: 0.762 | Test: 0.793\nEpoch 140 | Loss: 0.0038 | Train: 1.000 | Val: 0.780 | Test: 0.800\nEpoch 160 | Loss: 0.0059 | Train: 1.000 | Val: 0.774 | Test: 0.810\nEpoch 180 | Loss: 0.0095 | Train: 1.000 | Val: 0.772 | Test: 0.807\nEpoch 200 | Loss: 0.0033 | Train: 1.000 | Val: 0.774 | Test: 0.800\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# визуализация динамики ошибки\nplt.figure(figsize=(6, 4))\nplt.plot(train_losses, label=\"Train loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n# визуализация точности\nplt.figure(figsize=(6, 4))\nplt.plot(train_accs, label=\"Train acc\")\nplt.plot(val_accs, label=\"Val acc\")\nplt.plot(test_accs, label=\"Test acc\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:22:50.385743Z","iopub.execute_input":"2025-12-07T11:22:50.386047Z","iopub.status.idle":"2025-12-07T11:22:50.874119Z","shell.execute_reply.started":"2025-12-07T11:22:50.386026Z","shell.execute_reply":"2025-12-07T11:22:50.873127Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Вывод по пункту 1.1\n\nВ данной части реализована трёхслойная GCN-модель с нелинейностью ReLU в скрытых слоях и Dropout после второго сверточного слоя. На датасете Cora модель демонстрирует быстрый рост точности на обучающей выборке и достигает полного запоминания данных (`train accuracy = 1.0` уже к ~20-й эпохе).  \n\nВалидационная точность стабилизируется в диапазоне `0.768–0.780`, а максимальная тестовая точность достигает 0.811. Этот результат сопоставим с базовой двухслойной GCN из практики (`0.785`), но небольшое улучшение тестовой точности указывает на выигрыш от увеличения глубины.  \n\nСильный разрыв между `train accuracy (1.0)` и `val/test accuracy (~0.77–0.81)` свидетельствует о переобучении модели, что характерно для глубоких GCN на Cora. Dropout снижает выраженность переобучения: валидационная точность остаётся стабильной и не деградирует к концу обучения.  ","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Исследование глубины признакового пространства\n\nПроведите эксперимент с различными значениями скрытой размерности:\n\n```\nhidden_dim = 8, 16, 32, 64\n```\n\nПостройте таблицу:\n\n| Hidden Dim | Train Acc | Val Acc | Test Acc |\n|| ----| --| ---|\n\n**Вопросы:**\n\n- Сравните полученные результаты\n- Влияет ли размерность на качество обучения?\n","metadata":{"id":"KVfa8qYPaH5f"}},{"cell_type":"code","source":"# TODO\n\ndef run_gcn_experiment(hidden_dim, epochs=150, lr=0.01):\n    \"\"\"\n    Обучает трёхслойную GCN (та же архитектура, что в 1.1)\n    и возвращает final train/val/test accuracy.\n    \"\"\"\n    model = GCN3(\n        in_dim=data.num_features,\n        hidden_dim=hidden_dim,\n        out_dim=dataset.num_classes,\n        dropout=0.5\n    ).to(device)\n\n    optimizer = torch.optim.Adam(\n        model.parameters(),\n        lr=lr,\n        weight_decay=5e-4\n    )\n\n    best_val = 0\n    best_test = 0\n    last_train = 0\n\n    for epoch in range(epochs):\n        loss = train_node(model, data, optimizer)\n        train_acc, val_acc, test_acc = eval_node(model, data)\n\n        # сохраняем лучший val, и тест при этом val\n        if val_acc > best_val:\n            best_val = val_acc\n            best_test = test_acc\n\n        last_train = train_acc\n\n    return last_train, best_val, best_test\n\n\nhidden_dims = [8, 16, 32, 64]\nresults = []\n\nfor h in hidden_dims:\n    print(f\"Running hidden_dim = {h} ...\")\n    train_acc, val_acc, test_acc = run_gcn_experiment(h)\n    results.append({\n        \"Hidden Dim\": h,\n        \"Train Acc\": train_acc,\n        \"Val Acc\": val_acc,\n        \"Test Acc\": test_acc\n    })\n\ndf_hidden = pd.DataFrame(results)\ndf_hidden","metadata":{"id":"GJqx2YPycjsX","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:34:21.903663Z","iopub.execute_input":"2025-12-07T11:34:21.904601Z","iopub.status.idle":"2025-12-07T11:34:36.381071Z","shell.execute_reply.started":"2025-12-07T11:34:21.904571Z","shell.execute_reply":"2025-12-07T11:34:36.380221Z"}},"outputs":[{"name":"stdout","text":"Running hidden_dim = 8 ...\nRunning hidden_dim = 16 ...\nRunning hidden_dim = 32 ...\nRunning hidden_dim = 64 ...\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Hidden Dim  Train Acc  Val Acc  Test Acc\n0           8        1.0    0.750     0.752\n1          16        1.0    0.786     0.781\n2          32        1.0    0.786     0.805\n3          64        1.0    0.792     0.820","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hidden Dim</th>\n      <th>Train Acc</th>\n      <th>Val Acc</th>\n      <th>Test Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>1.0</td>\n      <td>0.750</td>\n      <td>0.752</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>1.0</td>\n      <td>0.786</td>\n      <td>0.781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>1.0</td>\n      <td>0.786</td>\n      <td>0.805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64</td>\n      <td>1.0</td>\n      <td>0.792</td>\n      <td>0.820</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Вывод по пункту 1.2\n\nВ эксперименте варьировалась скрытая размерность трёхслойной GCN-модели: `8, 16, 32` и `64`. Во всех случаях модель полностью осваивает обучающую выборку (`train accuracy = 1.0`), однако качество на валидации и тесте заметно зависит от размерности скрытого пространства.\n\nПри `hidden_dim = 8` валидационная и тестовая точности остаются на более низком уровне (`Val = 0.750`, `Test = 0.752`), что указывает на недостаточную выразительность модели. Увеличение размерности до `16` и `32` приводит к росту качества: для `hidden_dim = 32` достигаются `Val = 0.786` и `Test = 0.805`. Наибольшая тестовая точность наблюдается при `hidden_dim = 64` (`Val = 0.792`, `Test = 0.820`), что свидетельствует о дополнительном выигрыше от увеличения числа параметров.\n\nВ целом, небольшие значения скрытой размерности приводят к недообучению на уровне обобщения, тогда как диапазон 32–64 даёт более высокий баланс между выразительностью модели и качеством на валидации и тесте.","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Исследование нормализаций\n\nДобавьте BatchNorm / LayerNorm / PairNorm (можно комбинировать) между слоями GCN и сравните:\n\n- скорость сходимости,\n- валидационную точность,\n- чувствительность к learning rate.\n\n**Вопросы:**\n- Оцените каждый вариант:\n    - Улучшилась ли стабильность обучения?\n    - Снизился ли эффект over-smoothing?\n- Какой вариант нормализации показал себя лучше всего для данной задачи?\n\n","metadata":{"id":"3BpssDtpaLDE"}},{"cell_type":"code","source":"# TODO\nclass GCN3_BN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.bn2 = nn.BatchNorm1d(hidden_dim)\n\n        self.conv3 = GCNConv(hidden_dim, out_dim)\n\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n\n        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n\n        x = self.conv3(x, edge_index)\n        return x\n\n\nclass GCN3_LN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.ln1 = nn.LayerNorm(hidden_dim)\n\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.ln2 = nn.LayerNorm(hidden_dim)\n\n        self.conv3 = GCNConv(hidden_dim, out_dim)\n\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.ln1(self.conv1(x, edge_index)))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n\n        x = F.relu(self.ln2(self.conv2(x, edge_index)))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n\n        x = self.conv3(x, edge_index)\n        return x","metadata":{"id":"qd11RNlmcgoh","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:38:28.518156Z","iopub.execute_input":"2025-12-07T11:38:28.518591Z","iopub.status.idle":"2025-12-07T11:38:28.530276Z","shell.execute_reply.started":"2025-12-07T11:38:28.518563Z","shell.execute_reply":"2025-12-07T11:38:28.529247Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_and_eval_norm(model_class, hidden_dim=64, epochs=50):\n    model = model_class(\n        in_dim=data.num_features,\n        hidden_dim=hidden_dim,\n        out_dim=dataset.num_classes,\n        dropout=0.5\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\n    best_val = 0\n    best_test = 0\n    last_train = 0\n\n    for epoch in range(epochs):\n        loss = train_node(model, data, optimizer)\n        train_acc, val_acc, test_acc = eval_node(model, data)\n\n        if val_acc > best_val:\n            best_val = val_acc\n            best_test = test_acc\n\n        last_train = train_acc\n\n    return last_train, best_val, best_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:38:30.283034Z","iopub.execute_input":"2025-12-07T11:38:30.283365Z","iopub.status.idle":"2025-12-07T11:38:30.290726Z","shell.execute_reply.started":"2025-12-07T11:38:30.283342Z","shell.execute_reply":"2025-12-07T11:38:30.289619Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"results_norm = []\n\nprint(\"Running BatchNorm...\")\nbn_train, bn_val, bn_test = train_and_eval_norm(GCN3_BN)\nresults_norm.append({\n    \"Model\": \"GCN + BatchNorm\",\n    \"Train Acc\": bn_train,\n    \"Val Acc\": bn_val,\n    \"Test Acc\": bn_test\n})\n\nprint(\"Running LayerNorm...\")\nln_train, ln_val, ln_test = train_and_eval_norm(GCN3_LN)\nresults_norm.append({\n    \"Model\": \"GCN + LayerNorm\",\n    \"Train Acc\": ln_train,\n    \"Val Acc\": ln_val,\n    \"Test Acc\": ln_test\n})\n\ndf_norm = pd.DataFrame(results_norm)\ndf_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:38:53.583812Z","iopub.execute_input":"2025-12-07T11:38:53.584132Z","iopub.status.idle":"2025-12-07T11:38:57.553739Z","shell.execute_reply.started":"2025-12-07T11:38:53.584107Z","shell.execute_reply":"2025-12-07T11:38:57.552758Z"}},"outputs":[{"name":"stdout","text":"Running BatchNorm...\nRunning LayerNorm...\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"             Model  Train Acc  Val Acc  Test Acc\n0  GCN + BatchNorm        1.0    0.726     0.753\n1  GCN + LayerNorm        1.0    0.774     0.786","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Train Acc</th>\n      <th>Val Acc</th>\n      <th>Test Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GCN + BatchNorm</td>\n      <td>1.0</td>\n      <td>0.726</td>\n      <td>0.753</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GCN + LayerNorm</td>\n      <td>1.0</td>\n      <td>0.774</td>\n      <td>0.786</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Вывод по пункту 1.3\n\nВ эксперименте была оценена эффективность различных нормализаций в составе трёхслойной GCN: BatchNorm и LayerNorm. Оба варианта полностью осваивают обучающую выборку (`train accuracy = 1.0`), однако различаются по качеству на валидации и тесте.\n\nИспользование BatchNorm приводит к снижению валидационной точности до `0.726` и тестовой до `0.753`. Подобное снижение может быть связано с тем, что BatchNorm менее устойчива на нерегулярных структурах графов, где статистики активаций по батчу оказываются менее информативными.\n\nLayerNorm демонстрирует более высокое и стабильное качество (`Val = 0.774`, `Test = 0.786`), что делает её более подходящей нормализацией для графовых сверточных сетей. Нормализация по признаковому измерению уменьшает чувствительность к распределению соседей и не зависит от размера батча, что положительно влияет на обобщающую способность модели.\n\nТаким образом, LayerNorm улучшает стабильность обучения GNN на задаче классификации узлов, тогда как BatchNorm в данном случае снижает качество.","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Residual Connections (Skip Connections)\n\nДобавление остаточных связей:\n\n$\nh_v^{(k+1)} = h_v^{(k)} + \\text{GCNLayer}(h_v^{(k)})\n$\n\n— улучшает распространение градиентов и сохраняет индивидуальность узлов.\n\nЗадание:\n1. Добавьте residual connection между слоями GCN.\n2. Проверьте, можно ли теперь использовать более глубокую модель (3–4 слоя)\n\n**Вопросы:**\n\n* Улучшается ли обучение GCN?\n* Перестаёт ли сеть «слишком усреднять» узлы?\n\n","metadata":{"id":"CTiwRK0AcfGC"}},{"cell_type":"code","source":"# TODO\nclass ResidualGCN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, num_layers=4, dropout=0.5):\n        super().__init__()\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        self.convs = nn.ModuleList()\n        self.norms = nn.ModuleList()\n\n        # первый слой\n        self.convs.append(GCNConv(in_dim, hidden_dim))\n        self.norms.append(nn.LayerNorm(hidden_dim))\n\n        # промежуточные скрытые слои с одинаковой размерностью\n        for _ in range(num_layers - 2):\n            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n            self.norms.append(nn.LayerNorm(hidden_dim))\n\n        # выходной слой\n        self.convs.append(GCNConv(hidden_dim, out_dim))\n        # последний слой без нормализации\n        self.norms.append(nn.Identity())\n\n    def forward(self, x, edge_index):\n        h = x\n\n        for i in range(self.num_layers):\n            h_new = self.convs[i](h, edge_index)\n\n            # скрытые слои (кроме последнего) — ReLU, dropout и residual\n            if i < self.num_layers - 1:\n                h_new = self.norms[i](h_new)\n                h_new = F.relu(h_new)\n                h_new = F.dropout(h_new, p=self.dropout, training=self.training)\n\n                # residual connection (если совпадает размерность)\n                if h_new.shape == h.shape:\n                    h = h + h_new\n                else:\n                    h = h_new\n            else:\n                # выходной слой без residual и без dropout\n                h = h_new\n\n        return h","metadata":{"id":"Eqzq-zbsb7WJ","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:43:47.289650Z","iopub.execute_input":"2025-12-07T11:43:47.289978Z","iopub.status.idle":"2025-12-07T11:43:47.299724Z","shell.execute_reply.started":"2025-12-07T11:43:47.289955Z","shell.execute_reply":"2025-12-07T11:43:47.298665Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_residual_model(hidden_dim=64, epochs=150):\n    model = ResidualGCN(\n        in_dim=data.num_features,\n        hidden_dim=hidden_dim,\n        out_dim=dataset.num_classes,\n        num_layers=4,\n        dropout=0.5\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\n    best_val = 0\n    best_test = 0\n    last_train = 0\n\n    for epoch in range(epochs):\n        loss = train_node(model, data, optimizer)\n        train_acc, val_acc, test_acc = eval_node(model, data)\n\n        if val_acc > best_val:\n            best_val = val_acc\n            best_test = test_acc\n\n        last_train = train_acc\n\n        if epoch % 20 == 0 or epoch == 1:\n            print(f\"Epoch {epoch:03d} | Train={train_acc:.3f} | Val={val_acc:.3f} | Test={test_acc:.3f}\")\n\n    return last_train, best_val, best_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:44:01.937644Z","iopub.execute_input":"2025-12-07T11:44:01.937961Z","iopub.status.idle":"2025-12-07T11:44:01.945538Z","shell.execute_reply.started":"2025-12-07T11:44:01.937940Z","shell.execute_reply":"2025-12-07T11:44:01.944613Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"res_train, res_val, res_test = train_residual_model()\n\nprint(\"\\nResidual GCN results:\")\nprint(f\"Best Val Acc:  {res_val:.3f}\")\nprint(f\"Best Test Acc: {res_test:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:44:14.453357Z","iopub.execute_input":"2025-12-07T11:44:14.453699Z","iopub.status.idle":"2025-12-07T11:44:21.602083Z","shell.execute_reply.started":"2025-12-07T11:44:14.453676Z","shell.execute_reply":"2025-12-07T11:44:21.601107Z"}},"outputs":[{"name":"stdout","text":"Epoch 000 | Train=0.379 | Val=0.166 | Test=0.159\nEpoch 001 | Train=0.379 | Val=0.206 | Test=0.214\nEpoch 020 | Train=0.993 | Val=0.732 | Test=0.757\nEpoch 040 | Train=1.000 | Val=0.764 | Test=0.776\nEpoch 060 | Train=1.000 | Val=0.762 | Test=0.771\nEpoch 080 | Train=1.000 | Val=0.766 | Test=0.775\nEpoch 100 | Train=1.000 | Val=0.758 | Test=0.770\nEpoch 120 | Train=1.000 | Val=0.764 | Test=0.773\nEpoch 140 | Train=1.000 | Val=0.764 | Test=0.770\n\nResidual GCN results:\nBest Val Acc:  0.798\nBest Test Acc: 0.793\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Вывод по пункту 1.4\n\nВ данной части была исследована GCN-модель с остаточными связями, позволяющими передавать информацию между слоями без потери исходных признаков. Такой механизм упрощает распространение градиентов и снижает эффект деградации при увеличении глубины сети.  \n\nЧетырёхслойная Residual GCN показала устойчивое обучение: валидационная точность выросла до `0.798`, что превышает показатели базовой трёхслойной модели. Это подтверждает, что остаточные связи облегчают оптимизацию более глубоких GNN.  \n\nТестовая точность достигает `0.793`, что немного ниже максимальных значений предыдущих экспериментов. Подобный результат указывает на то, что более глубокая архитектура с residual-механизмом лучше согласуется с данными валидации, но не всегда приводит к росту тестового качества. Тем не менее, использование остаточных связей делает обучение глубоких графовых сетей значительно стабильнее.","metadata":{}},{"cell_type":"markdown","source":"### 1.5 DropEdge\n\nDropEdge случайно удаляет часть рёбер:\n\n$\n\\tilde{E} = \\text{Dropout}(E)\n$\n\nЭтот метод:\n- уменьшает степень узлов,\n- снижает oversmoothing,\n- действует как регуляризация.\n\nЗадание:\n1. Реализуйте DropEdge: случайно удаляйте `p` рёбер на каждой эпохе.\n2. Обучите GCN на этом изменённом графе.\n3. Постройте метрики качества.\n\n**Вопросы:**\n- Улучшается ли устойчивость сети к переобучению?\n- Какой процент удаляемых рёбер оптимален?","metadata":{"id":"69H4eoF2dKnC"}},{"cell_type":"code","source":"# TODO\ndef train_with_dropedge(model, data, optimizer, p=0.2):\n    \"\"\"\n    Обучение GCN с DropEdge: на каждой эпохе случайно удаляется часть рёбер.\n    \"\"\"\n    model.train()\n    optimizer.zero_grad()\n\n    # формируем подграф с редуцированным числом рёбер\n    edge_index_dropped, _ = dropout_edge(data.edge_index, p=p, training=True)\n\n    out = model(data.x, edge_index_dropped)\n    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()","metadata":{"id":"hKYw3am2dJ5O","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:49:28.425274Z","iopub.execute_input":"2025-12-07T11:49:28.425998Z","iopub.status.idle":"2025-12-07T11:49:28.431728Z","shell.execute_reply.started":"2025-12-07T11:49:28.425963Z","shell.execute_reply":"2025-12-07T11:49:28.430679Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def run_dropedge_experiment(p, hidden_dim=64, epochs=150):\n    model = GCN3(\n        in_dim=data.num_features,\n        hidden_dim=hidden_dim,\n        out_dim=dataset.num_classes,\n        dropout=0.5\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\n    best_val = 0\n    best_test = 0\n    last_train = 0\n\n    for epoch in range(epochs):\n        loss = train_with_dropedge(model, data, optimizer, p=p)\n        train_acc, val_acc, test_acc = eval_node(model, data)\n\n        if val_acc > best_val:\n            best_val = val_acc\n            best_test = test_acc\n\n        last_train = train_acc\n\n        if epoch % 40 == 0 or epoch == 1:\n            print(f\"[p={p}] Epoch {epoch:03d} | Train={train_acc:.3f} | Val={val_acc:.3f} | Test={test_acc:.3f}\")\n\n    return last_train, best_val, best_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:49:37.123046Z","iopub.execute_input":"2025-12-07T11:49:37.123361Z","iopub.status.idle":"2025-12-07T11:49:37.130340Z","shell.execute_reply.started":"2025-12-07T11:49:37.123339Z","shell.execute_reply":"2025-12-07T11:49:37.129466Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\n\nresults_drop = []\n\nfor p in [0.0, 0.2, 0.5]:\n    print(f\"\\nRunning DropEdge with p={p} ...\")\n    train_acc, val_acc, test_acc = run_dropedge_experiment(p)\n    results_drop.append({\n        \"DropEdge p\": p,\n        \"Train Acc\": train_acc,\n        \"Val Acc\": val_acc,\n        \"Test Acc\": test_acc\n    })\n\ndf_dropedge = pd.DataFrame(results_drop)\ndf_dropedge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:49:49.791215Z","iopub.execute_input":"2025-12-07T11:49:49.792019Z","iopub.status.idle":"2025-12-07T11:50:05.925220Z","shell.execute_reply.started":"2025-12-07T11:49:49.791988Z","shell.execute_reply":"2025-12-07T11:50:05.924244Z"}},"outputs":[{"name":"stdout","text":"\nRunning DropEdge with p=0.0 ...\n[p=0.0] Epoch 000 | Train=0.593 | Val=0.436 | Test=0.469\n[p=0.0] Epoch 001 | Train=0.871 | Val=0.616 | Test=0.645\n[p=0.0] Epoch 040 | Train=1.000 | Val=0.748 | Test=0.769\n[p=0.0] Epoch 080 | Train=1.000 | Val=0.762 | Test=0.781\n[p=0.0] Epoch 120 | Train=1.000 | Val=0.756 | Test=0.770\n\nRunning DropEdge with p=0.2 ...\n[p=0.2] Epoch 000 | Train=0.493 | Val=0.258 | Test=0.287\n[p=0.2] Epoch 001 | Train=0.850 | Val=0.586 | Test=0.592\n[p=0.2] Epoch 040 | Train=0.993 | Val=0.770 | Test=0.783\n[p=0.2] Epoch 080 | Train=1.000 | Val=0.748 | Test=0.763\n[p=0.2] Epoch 120 | Train=1.000 | Val=0.748 | Test=0.752\n\nRunning DropEdge with p=0.5 ...\n[p=0.5] Epoch 000 | Train=0.643 | Val=0.562 | Test=0.566\n[p=0.5] Epoch 001 | Train=0.793 | Val=0.636 | Test=0.665\n[p=0.5] Epoch 040 | Train=1.000 | Val=0.730 | Test=0.762\n[p=0.5] Epoch 080 | Train=1.000 | Val=0.744 | Test=0.784\n[p=0.5] Epoch 120 | Train=1.000 | Val=0.766 | Test=0.768\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   DropEdge p  Train Acc  Val Acc  Test Acc\n0         0.0        1.0    0.786     0.798\n1         0.2        1.0    0.792     0.804\n2         0.5        1.0    0.794     0.815","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DropEdge p</th>\n      <th>Train Acc</th>\n      <th>Val Acc</th>\n      <th>Test Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.786</td>\n      <td>0.798</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>0.792</td>\n      <td>0.804</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.794</td>\n      <td>0.815</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Вывод по пункту 1.5\n\nМетод DropEdge был применён с вероятностями удаления рёбер `p ∈ {0.0, 0.2, 0.5}`. Во всех случаях модель достигает полного освоения обучающей выборки (`train accuracy = 1.0`), однако качество на валидации и тесте существенно различается.\n\nПри `p = 0.0` (без DropEdge) тестовая точность составляет `0.798`. Добавление умеренного уровня стохастического шума в структуру графа приводит к повышению качества: при `p = 0.2` тестовая точность возрастает до `0.804`, а при `p = 0.5` достигает максимального значения `0.815`. Это указывает на то, что DropEdge выполняет роль эффективной регуляризации, снижая переобучение и позволяя модели лучше обобщать на тестовой выборке.\n\nСлишком большие значения вероятности удаления рёбер могут разрушать значимую структуру графа, однако в диапазоне `p ∈ [0.2, 0.5]` наблюдается стабильный рост качества, что подтверждает устойчивость GCN к частичному стохастическому разрежению графа.","metadata":{}},{"cell_type":"markdown","source":"### 1.6 Исследование различных архитектур\nВыберите 2 базовые архитектуры из списка: GraphSAGE, GAT(v2), GIN. Реализуйте их для задачи node classification и сравните полученные результаты.\n\nКомментарий: при реализации, можно использовать наработки с предыдущих пунктов - добавлять разные виды модификаций (увеличивать число слоев / добавлять слои нормализации / residual conections...)","metadata":{"id":"rsCOW9frdgv4"}},{"cell_type":"code","source":"# TODO\n\n# GraphSAGE\nclass SAGENet(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n        super().__init__()\n        self.conv1 = SAGEConv(in_dim, hidden_dim)\n        self.conv2 = SAGEConv(hidden_dim, out_dim)\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n\n\n# GATv2\nclass GATv2Net(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, heads=4, dropout=0.6):\n        super().__init__()\n        # первый слой: multi-head attention\n        self.conv1 = GATv2Conv(\n            in_channels=in_dim,\n            out_channels=hidden_dim,\n            heads=heads,\n            dropout=dropout\n        )\n        # второй слой: 1 head, без конкатенации\n        self.conv2 = GATv2Conv(\n            in_channels=hidden_dim * heads,\n            out_channels=out_dim,\n            heads=1,\n            concat=False,\n            dropout=dropout\n        )\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n\n\ndef train_and_eval_architecture(model_cls, name, epochs=200, hidden_dim=64):\n    \"\"\"\n    Обучает заданную архитектуру и возвращает финальные метрики.\n    \"\"\"\n    model = model_cls(\n        in_dim=data.num_features,\n        hidden_dim=hidden_dim,\n        out_dim=dataset.num_classes\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n\n    best_val = 0\n    best_test = 0\n    last_train = 0\n\n    for epoch in range(epochs):\n        loss = train_node(model, data, optimizer)\n        train_acc, val_acc, test_acc = eval_node(model, data)\n\n        if val_acc > best_val:\n            best_val = val_acc\n            best_test = test_acc\n\n        last_train = train_acc\n\n        if epoch % 40 == 0 or epoch == 1:\n            print(f\"[{name}] Epoch {epoch:03d} | \"\n                  f\"Train={train_acc:.3f} | Val={val_acc:.3f} | Test={test_acc:.3f}\")\n\n    return last_train, best_val, best_test","metadata":{"id":"cWbzK6zNexYz","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:53:37.295907Z","iopub.execute_input":"2025-12-07T11:53:37.296278Z","iopub.status.idle":"2025-12-07T11:53:37.308568Z","shell.execute_reply.started":"2025-12-07T11:53:37.296253Z","shell.execute_reply":"2025-12-07T11:53:37.307552Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"results_arch = []\n\nprint(\"Training GraphSAGE...\")\nsage_train, sage_val, sage_test = train_and_eval_architecture(SAGENet, \"GraphSAGE\")\nresults_arch.append({\n    \"Model\": \"GraphSAGE\",\n    \"Train Acc\": sage_train,\n    \"Val Acc\": sage_val,\n    \"Test Acc\": sage_test\n})\n\nprint(\"\\nTraining GATv2...\")\ngat_train, gat_val, gat_test = train_and_eval_architecture(GATv2Net, \"GATv2\")\nresults_arch.append({\n    \"Model\": \"GATv2\",\n    \"Train Acc\": gat_train,\n    \"Val Acc\": gat_val,\n    \"Test Acc\": gat_test\n})\n\ndf_arch = pd.DataFrame(results_arch)\ndf_arch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:53:40.033745Z","iopub.execute_input":"2025-12-07T11:53:40.034052Z","iopub.status.idle":"2025-12-07T11:54:39.273253Z","shell.execute_reply.started":"2025-12-07T11:53:40.034031Z","shell.execute_reply":"2025-12-07T11:54:39.272479Z"}},"outputs":[{"name":"stdout","text":"Training GraphSAGE...\n[GraphSAGE] Epoch 000 | Train=0.750 | Val=0.400 | Test=0.380\n[GraphSAGE] Epoch 001 | Train=0.971 | Val=0.642 | Test=0.628\n[GraphSAGE] Epoch 040 | Train=1.000 | Val=0.768 | Test=0.795\n[GraphSAGE] Epoch 080 | Train=1.000 | Val=0.776 | Test=0.799\n[GraphSAGE] Epoch 120 | Train=1.000 | Val=0.776 | Test=0.812\n[GraphSAGE] Epoch 160 | Train=1.000 | Val=0.776 | Test=0.803\n\nTraining GATv2...\n[GATv2] Epoch 000 | Train=0.757 | Val=0.594 | Test=0.610\n[GATv2] Epoch 001 | Train=0.871 | Val=0.664 | Test=0.697\n[GATv2] Epoch 040 | Train=1.000 | Val=0.754 | Test=0.784\n[GATv2] Epoch 080 | Train=1.000 | Val=0.752 | Test=0.789\n[GATv2] Epoch 120 | Train=1.000 | Val=0.756 | Test=0.791\n[GATv2] Epoch 160 | Train=1.000 | Val=0.758 | Test=0.794\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"       Model  Train Acc  Val Acc  Test Acc\n0  GraphSAGE        1.0    0.784     0.797\n1      GATv2        1.0    0.768     0.799","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Train Acc</th>\n      <th>Val Acc</th>\n      <th>Test Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GraphSAGE</td>\n      <td>1.0</td>\n      <td>0.784</td>\n      <td>0.797</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GATv2</td>\n      <td>1.0</td>\n      <td>0.768</td>\n      <td>0.799</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"### Вывод по пункту 1.6\n\nВ данном пункте сравнивались две архитектуры графовых нейросетей для задачи классификации узлов на Cora: GraphSAGE и GATv2. Обе модели достигают полной точности на обучающей выборке (`train accuracy = 1.0`), однако различаются по качеству на валидации и тесте.\n\nGraphSAGE показывает валидационную точность `0.784` и тестовую `0.797`. Архитектура использует агрегацию признаков соседних узлов (mean-пул), что позволяет эффективно усреднять локальный контекст и даёт стабильное качество на разреженном графе цитирований.\n\nGATv2 достигает валидационной точности `0.768` и тестовой `0.799`. Механизм внимательного агрегирования соседей позволяет по-разному взвешивать связи, что приводит к сопоставимому с GraphSAGE качеству на тестовой выборке, но несколько более низким показателям на валидации.\n\nТаким образом, обе архитектуры демонстрируют близкие результаты и превосходят базовую GCN по качеству обобщения. GraphSAGE обеспечивает немного более высокую валидационную точность и стабильность, тогда как GATv2 достигает максимальной тестовой точности, оставаясь чувствительным к настройке гиперпараметров и регуляризации.","metadata":{}},{"cell_type":"markdown","source":"# Часть 2. Link Prediction","metadata":{"id":"Cyxi5m5dgGxP"}},{"cell_type":"markdown","source":"### 2.1 Реализация MLP-декодера\n\nВместо dot-product декодера:\n\n$\ns_{uv} = z_u^\\top z_v\n$\n\nреализуйте:\n\n$\ns_{uv} = \\mathrm{MLP}([z_u ,||, z_v])\n$\n\nСравните качество (AUC, AP) с dot-product.","metadata":{"id":"HaLFvBNlgMdC"}},{"cell_type":"code","source":"# TODO\ntransform = RandomLinkSplit(\n    num_val=0.05,\n    num_test=0.10,\n    is_undirected=True,\n    add_negative_train_samples=True,\n)\n\ntrain_data, val_data, test_data = transform(data)\ntrain_data, val_data, test_data = train_data.to(device), val_data.to(device), test_data.to(device)\n\ntrain_data, val_data, test_data","metadata":{"id":"UbDJxOF6gkf1","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T11:58:40.194540Z","iopub.execute_input":"2025-12-07T11:58:40.194873Z","iopub.status.idle":"2025-12-07T11:58:40.214685Z","shell.execute_reply.started":"2025-12-07T11:58:40.194839Z","shell.execute_reply":"2025-12-07T11:58:40.213622Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[8976], edge_label_index=[2, 8976]),\n Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[526], edge_label_index=[2, 526]),\n Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[1054], edge_label_index=[2, 1054]))"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"class GCNEncoder(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.conv2(x, edge_index)\n        return x\n\ndef decode_dot(z, edge_index):\n    src, dst = edge_index\n    return (z[src] * z[dst]).sum(dim=1)\n    \nclass MLPDecoder(nn.Module):\n    def __init__(self, in_dim, hidden_dim=64):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(2 * in_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, z, edge_index):\n        src, dst = edge_index\n        x = torch.cat([z[src], z[dst]], dim=1)\n        return self.mlp(x).squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:00:06.023352Z","iopub.execute_input":"2025-12-07T12:00:06.023714Z","iopub.status.idle":"2025-12-07T12:00:06.032065Z","shell.execute_reply.started":"2025-12-07T12:00:06.023690Z","shell.execute_reply":"2025-12-07T12:00:06.030888Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def train_lp(encoder, decoder, data, optimizer):\n    encoder.train()\n    if hasattr(decoder, \"train\"):\n        decoder.train()\n\n    optimizer.zero_grad()\n\n    z = encoder(data.x, data.edge_index)\n\n    logits = decoder(z, data.edge_label_index)\n    labels = data.edge_label.float()\n\n    loss = F.binary_cross_entropy_with_logits(logits, labels)\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n\n\n@torch.no_grad()\ndef eval_lp(encoder, decoder, data):\n    encoder.eval()\n    if hasattr(decoder, \"eval\"):\n        decoder.eval()\n\n    z = encoder(data.x, data.edge_index)\n\n    logits = decoder(z, data.edge_label_index)\n    probs = torch.sigmoid(logits).cpu().numpy()\n    labels = data.edge_label.cpu().numpy()\n\n    auc = roc_auc_score(labels, probs)\n    ap = average_precision_score(labels, probs)\n    return auc, ap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:05:22.076227Z","iopub.execute_input":"2025-12-07T12:05:22.076579Z","iopub.status.idle":"2025-12-07T12:05:22.084996Z","shell.execute_reply.started":"2025-12-07T12:05:22.076551Z","shell.execute_reply":"2025-12-07T12:05:22.083615Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"hidden_dim = 64\nepochs = 80\n\nresults_lp = []\n\n# DOT PRODUCT \nencoder_dot = GCNEncoder(data.num_features, hidden_dim).to(device)\ndecoder_dot = lambda z, e: decode_dot(z, e)\n\noptimizer_dot = torch.optim.Adam(encoder_dot.parameters(), lr=0.01)\n\nfor epoch in range(epochs):\n    loss = train_lp(encoder_dot, decoder_dot, train_data, optimizer_dot)\n    if epoch % 20 == 0:\n        print(f\"[DOT] Epoch {epoch} | Loss={loss:.4f}\")\n\ndot_val = eval_lp(encoder_dot, decoder_dot, val_data)\ndot_test = eval_lp(encoder_dot, decoder_dot, test_data)\n\n\n# MLP DECODER \nencoder_mlp = GCNEncoder(data.num_features, hidden_dim).to(device)\ndecoder_mlp = MLPDecoder(hidden_dim).to(device)\n\noptimizer_mlp = torch.optim.Adam(\n    list(encoder_mlp.parameters()) + list(decoder_mlp.parameters()),\n    lr=0.01\n)\n\nfor epoch in range(epochs):\n    loss = train_lp(encoder_mlp, decoder_mlp, train_data, optimizer_mlp)\n    if epoch % 20 == 0:\n        print(f\"[MLP] Epoch {epoch} | Loss={loss:.4f}\")\n\nmlp_val = eval_lp(encoder_mlp, decoder_mlp, val_data)\nmlp_test = eval_lp(encoder_mlp, decoder_mlp, test_data)\n\n\n# Итоговая таблица\ndf_lp = pd.DataFrame({\n    \"Decoder\": [\"Dot product\", \"MLP\"],\n    \"Val AUC\": [dot_val[0], mlp_val[0]],\n    \"Val AP\":  [dot_val[1], mlp_val[1]],\n    \"Test AUC\": [dot_test[0], mlp_test[0]],\n    \"Test AP\":  [dot_test[1], mlp_test[1]],\n})\n\ndf_lp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:05:24.870576Z","iopub.execute_input":"2025-12-07T12:05:24.870909Z","iopub.status.idle":"2025-12-07T12:05:30.508132Z","shell.execute_reply.started":"2025-12-07T12:05:24.870886Z","shell.execute_reply":"2025-12-07T12:05:30.507187Z"}},"outputs":[{"name":"stdout","text":"[DOT] Epoch 0 | Loss=0.6725\n[DOT] Epoch 20 | Loss=0.4911\n[DOT] Epoch 40 | Loss=0.3266\n[DOT] Epoch 60 | Loss=0.1915\n[MLP] Epoch 0 | Loss=0.6936\n[MLP] Epoch 20 | Loss=0.5068\n[MLP] Epoch 40 | Loss=0.1976\n[MLP] Epoch 60 | Loss=0.0571\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       Decoder   Val AUC    Val AP  Test AUC   Test AP\n0  Dot product  0.785077  0.757951  0.807901  0.779408\n1          MLP  0.728896  0.744260  0.760153  0.780203","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Decoder</th>\n      <th>Val AUC</th>\n      <th>Val AP</th>\n      <th>Test AUC</th>\n      <th>Test AP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dot product</td>\n      <td>0.785077</td>\n      <td>0.757951</td>\n      <td>0.807901</td>\n      <td>0.779408</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MLP</td>\n      <td>0.728896</td>\n      <td>0.744260</td>\n      <td>0.760153</td>\n      <td>0.780203</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"### Вывод по пункту 2.1\n\nВ задаче предсказания рёбер были сравнены два варианта декодера поверх общего GCN-энкодера: скалярное произведение (dot product) и MLP-декодер, применяемый к конкатенации эмбеддингов пар узлов.\n\nDot-product-декодер показал более высокое качество по `AUC` как на валидационной, так и на тестовой выборках (`Val AUC = 0.785`, `Test AUC = 0.808`), при этом средняя точность (`AP`) также остаётся на высоком уровне (`Val AP = 0.758`, `Test AP = 0.779`). MLP-декодер продемонстрировал меньшие значения `AUC` (`Val AUC = 0.729`, `Test AUC = 0.760`), при схожих значениях `AP` (`Val AP = 0.744`, `Test AP = 0.780`).\n\nРезультаты показывают, что для данного энкодера и текущего объёма обучающих данных простая схема с dot-product оказывается более эффективной по интегральной метрике качества (`AUC`). MLP-декодер обладает большей выразительностью, но требует более тщательной настройки гиперпараметров и регуляризации; при выбранной конфигурации он склонен к переобучению и уступает по `AUC` линейному декодеру на основе скалярного произведения.","metadata":{}},{"cell_type":"markdown","source":"### 2.2 Эксперимент с negative sampling ratio\n\nПопробуйте соотношения:\n\n```\n1:1, 1:2, 1:5, 1:10\n```\n\nПостройте таблицу для AUC и AP. Опишите полученные результаты\n","metadata":{"id":"TiFCnvzuga7C"}},{"cell_type":"code","source":"# TODO\ndef make_split(ratio):\n    transform = RandomLinkSplit(\n        num_val=0.05,\n        num_test=0.10,\n        is_undirected=True,\n        add_negative_train_samples=True,\n        neg_sampling_ratio=ratio,\n    )\n    train_d, val_d, test_d = transform(data)\n    return train_d.to(device), val_d.to(device), test_d.to(device)\n\ndef train_lp_simple(encoder, data, optimizer):\n    encoder.train()\n    optimizer.zero_grad()\n\n    z = encoder(data.x, data.edge_index)\n    src, dst = data.edge_label_index\n\n    logits = (z[src] * z[dst]).sum(dim=1)\n    labels = data.edge_label.float()\n\n    loss = F.binary_cross_entropy_with_logits(logits, labels)\n\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n\n@torch.no_grad()\ndef eval_lp_simple(encoder, data):\n    encoder.eval()\n    z = encoder(data.x, data.edge_index)\n\n    src, dst = data.edge_label_index\n    logits = (z[src] * z[dst]).sum(dim=1)\n\n    probs = torch.sigmoid(logits).cpu().numpy()\n    labels = data.edge_label.cpu().numpy()\n\n    auc = roc_auc_score(labels, probs)\n    ap = average_precision_score(labels, probs)\n    return auc, ap","metadata":{"id":"aVvbNftSgnvb","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:08:07.114835Z","iopub.execute_input":"2025-12-07T12:08:07.115171Z","iopub.status.idle":"2025-12-07T12:08:07.123832Z","shell.execute_reply.started":"2025-12-07T12:08:07.115148Z","shell.execute_reply":"2025-12-07T12:08:07.122678Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"ratios = [1, 2, 5, 10]\nepochs = 60\nhidden_dim = 64\n\nresults_ratio = []\n\nfor r in ratios:\n    print(f\"\\n=== Negative sampling ratio = {r} ===\")\n\n    # создаём новый train/val/test для данного ratio\n    train_d, val_d, test_d = make_split(r)\n\n    # создаём encoder\n    encoder = GCNEncoder(data.num_features, hidden_dim).to(device)\n    optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n\n    # тренировка\n    for epoch in range(epochs):\n        loss = train_lp_simple(encoder, train_d, optimizer)\n        if epoch % 20 == 0:\n            print(f\"Epoch {epoch} | Loss={loss:.4f}\")\n\n    # оценка\n    val_auc, val_ap = eval_lp_simple(encoder, val_d)\n    test_auc, test_ap = eval_lp_simple(encoder, test_d)\n\n    results_ratio.append({\n        \"Neg Ratio\": r,\n        \"Val AUC\": val_auc,\n        \"Val AP\": val_ap,\n        \"Test AUC\": test_auc,\n        \"Test AP\": test_ap\n    })\n\ndf_ratio = pd.DataFrame(results_ratio)\ndf_ratio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:08:28.876119Z","iopub.execute_input":"2025-12-07T12:08:28.876512Z","iopub.status.idle":"2025-12-07T12:08:40.208194Z","shell.execute_reply.started":"2025-12-07T12:08:28.876488Z","shell.execute_reply":"2025-12-07T12:08:40.207421Z"}},"outputs":[{"name":"stdout","text":"\n=== Negative sampling ratio = 1 ===\nEpoch 0 | Loss=0.6736\nEpoch 20 | Loss=0.4897\nEpoch 40 | Loss=0.3718\n\n=== Negative sampling ratio = 2 ===\nEpoch 0 | Loss=0.7007\nEpoch 20 | Loss=0.4966\nEpoch 40 | Loss=0.3367\n\n=== Negative sampling ratio = 5 ===\nEpoch 0 | Loss=0.7185\nEpoch 20 | Loss=0.6905\nEpoch 40 | Loss=0.6491\n\n=== Negative sampling ratio = 10 ===\nEpoch 0 | Loss=0.7262\nEpoch 20 | Loss=0.6944\nEpoch 40 | Loss=0.6933\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   Neg Ratio   Val AUC    Val AP  Test AUC   Test AP\n0          1  0.828601  0.805829  0.837788  0.827723\n1          2  0.810475  0.708606  0.783962  0.642069\n2          5  0.731228  0.387457  0.756531  0.414000\n3         10  0.509003  0.098839  0.515997  0.106250","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neg Ratio</th>\n      <th>Val AUC</th>\n      <th>Val AP</th>\n      <th>Test AUC</th>\n      <th>Test AP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.828601</td>\n      <td>0.805829</td>\n      <td>0.837788</td>\n      <td>0.827723</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.810475</td>\n      <td>0.708606</td>\n      <td>0.783962</td>\n      <td>0.642069</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>0.731228</td>\n      <td>0.387457</td>\n      <td>0.756531</td>\n      <td>0.414000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>0.509003</td>\n      <td>0.098839</td>\n      <td>0.515997</td>\n      <td>0.106250</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"### Вывод по пункту 2.2\n\nВ данном эксперименте исследовалось влияние отношения числа негативных примеров к числу позитивных (negative sampling ratio) на качество модели предсказания рёбер. Рассматривались значения `ratio ∈ {1, 2, 5, 10}` для GCN-энкодера с dot-product-декодером.\n\nПри `ratio = 1` (соотношение 1:1) достигаются наилучшие показатели: `Val AUC = 0.829`, `Val AP = 0.806`, `Test AUC = 0.838`, `Test AP = 0.828`. Увеличение отношения до `ratio = 2` приводит к снижению качества: `Val AUC` падает до `0.810`, а `Test AUC` — до `0.784`, при этом средняя точность (AP) существенно уменьшается (особенно на тесте, до 0.642). При дальнейшем росте числа негативных примеров (`ratio = 5` и `10`) метрики деградируют ещё сильнее: при `ratio = 10` значения AUC и AP близки к случайному угадыванию (Val AUC ≈ 0.51, Val AP ≈ 0.10).\n\nРезультаты показывают, что умеренное количество негативных примеров (около 1:1) обеспечивает наилучший баланс между количеством обучающих сигналов и сложностью задачи. Чрезмерное увеличение доли негативных рёбер смещает распределение классов, делает задачу сильно несбалансированной и затрудняет обучение, что приводит к резкому падению `AUC` и `AP`.","metadata":{}},{"cell_type":"markdown","source":"### 2.3 Оптизация текущей модели\nПопробуйте улучшить текущую модель за счет использования следующих модификаций:\n- добавление нормализации (BatchNorm / LayerNorm / PairNorm)\n- Dropout\n- residual connection\n\nОпишите полученные результаты\n","metadata":{"id":"s2kFom4JhWnK"}},{"cell_type":"code","source":"# TODO\nclass GCNEncoder_Dropout(nn.Module):\n    def __init__(self, in_dim, hidden_dim, dropout=0.5):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.dropout = dropout\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n\nclass GCNEncoder_LN(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.ln1 = nn.LayerNorm(hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.ln2 = nn.LayerNorm(hidden_dim)\n\n    def forward(self, x, edge_index):\n        x = self.ln1(F.relu(self.conv1(x, edge_index)))\n        x = self.ln2(self.conv2(x, edge_index))\n        return x\n\nclass GCNEncoder_Residual(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n\n    def forward(self, x, edge_index):\n        h = F.relu(self.conv1(x, edge_index))\n        h2 = self.conv2(h, edge_index)\n\n        # residual connection\n        if h2.shape == h.shape:\n            return h + h2\n        else:\n            return h2","metadata":{"id":"TMBC27pZi7xO","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:11:17.762756Z","iopub.execute_input":"2025-12-07T12:11:17.763053Z","iopub.status.idle":"2025-12-07T12:11:17.772736Z","shell.execute_reply.started":"2025-12-07T12:11:17.763033Z","shell.execute_reply":"2025-12-07T12:11:17.771677Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"train_d, val_d, test_d = make_split(1)\n\nhidden_dim = 64\nepochs = 60\n\narchitectures = {\n    \"Dropout\": GCNEncoder_Dropout,\n    \"LayerNorm\": GCNEncoder_LN,\n    \"Residual\": GCNEncoder_Residual,\n}\n\nresults_opt = []\n\nfor name, model_cls in architectures.items():\n    print(f\"\\n=== Training {name} model ===\")\n    encoder = model_cls(data.num_features, hidden_dim).to(device)\n    optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n\n    for epoch in range(epochs):\n        loss = train_lp_simple(encoder, train_d, optimizer)\n        if epoch % 20 == 0:\n            print(f\"{name} | Epoch {epoch} | Loss={loss:.4f}\")\n\n    val_auc, val_ap = eval_lp_simple(encoder, val_d)\n    test_auc, test_ap = eval_lp_simple(encoder, test_d)\n\n    results_opt.append({\n        \"Model\": name,\n        \"Val AUC\": val_auc,\n        \"Val AP\": val_ap,\n        \"Test AUC\": test_auc,\n        \"Test AP\": test_ap\n    })\n\ndf_opt = pd.DataFrame(results_opt)\ndf_opt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:11:33.043242Z","iopub.execute_input":"2025-12-07T12:11:33.043604Z","iopub.status.idle":"2025-12-07T12:11:38.632832Z","shell.execute_reply.started":"2025-12-07T12:11:33.043579Z","shell.execute_reply":"2025-12-07T12:11:38.631967Z"}},"outputs":[{"name":"stdout","text":"\n=== Training Dropout model ===\nDropout | Epoch 0 | Loss=0.6618\nDropout | Epoch 20 | Loss=0.5220\nDropout | Epoch 40 | Loss=0.4118\n\n=== Training LayerNorm model ===\nLayerNorm | Epoch 0 | Loss=7.2929\nLayerNorm | Epoch 20 | Loss=0.9185\nLayerNorm | Epoch 40 | Loss=0.1999\n\n=== Training Residual model ===\nResidual | Epoch 0 | Loss=0.6573\nResidual | Epoch 20 | Loss=0.3708\nResidual | Epoch 40 | Loss=0.1793\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"       Model   Val AUC    Val AP  Test AUC   Test AP\n0    Dropout  0.872530  0.864986  0.887163  0.890691\n1  LayerNorm  0.850410  0.855079  0.874289  0.876883\n2   Residual  0.821408  0.835532  0.844977  0.856435","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Val AUC</th>\n      <th>Val AP</th>\n      <th>Test AUC</th>\n      <th>Test AP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dropout</td>\n      <td>0.872530</td>\n      <td>0.864986</td>\n      <td>0.887163</td>\n      <td>0.890691</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LayerNorm</td>\n      <td>0.850410</td>\n      <td>0.855079</td>\n      <td>0.874289</td>\n      <td>0.876883</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Residual</td>\n      <td>0.821408</td>\n      <td>0.835532</td>\n      <td>0.844977</td>\n      <td>0.856435</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"### Вывод по пункту 2.3\n\nВ данном пункте исследовалось влияние трёх архитектурных модификаций GCN-энкодера на качество задачи предсказания рёбер при фиксированном отношении положительных и отрицательных примеров (1:1). Рассматривались варианты с добавлением Dropout, LayerNorm и residual-соединений.\n\nНаилучшие результаты продемонстрировала модель с Dropout: `Val AUC = 0.873`, `Test AUC = 0.887` и `Test AP = 0.891`. Добавление стохастического отключения нейронов снижает переобучение и способствует более устойчивому обучению, что отражается в максимальных значениях `AU`C и `AP` среди протестированных вариантов.\n\nМодель с LayerNorm показала несколько более низкие результаты (`Val AUC = 0.850`, `Test AUC = 0.874`), но сохраняет высокую точность и стабильность. Нормализация по признаковому измерению улучшает устойчивость оптимизации, особенно на ранних этапах обучения, однако в данной конфигурации уступает варианту с Dropout.\n\nResidual-модификация обеспечивает рост устойчивости градиента и облегчает обучение, однако итоговые метрики оказались заметно ниже (`Val AUC = 0.821`, `Test AUC = 0.845`). Это согласуется с тем, что добавление остаточных связей преимущественно улучшает обучение глубоких GNN, но не всегда приводит к повышению качества в задачах линк-предсказания с малой глубиной энкодера.\n\nВ совокупности результаты показывают, что Dropout является наиболее эффективным механизмом регуляризации для данной постановки LP-задачи.","metadata":{}},{"cell_type":"markdown","source":"### 2.4 Реализация и сравнение GCN / GraphSAGE / GAT / GIN\nВыберите 2 базовые архитектуры из списка: GraphSAGE, GAT(v2), GIN. Реализуйте их для задачи node classification и сравните полученные результаты.\n\nКомментарий: при реализации, можно использовать наработки с предыдущих пунктов - добавлять разные виды модификаций (увеличивать число слоев / добавлять слои нормализации / residual conections...)\n","metadata":{"id":"b1qEP0hth_x8"}},{"cell_type":"code","source":"# TODO\nclass GCNEncoder_simple(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.conv2(x, edge_index)\n        return x\n\n\nclass SAGEEncoder(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.conv1 = SAGEConv(in_dim, hidden_dim)\n        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.conv2(x, edge_index)\n        return x\n\n\nclass GINEncoder(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        nn_mlp1 = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n        )\n        nn_mlp2 = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n        )\n        self.conv1 = GINConv(nn_mlp1)\n        self.conv2 = GINConv(nn_mlp2)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"id":"LdMSJwojipnj","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:23:44.536048Z","iopub.execute_input":"2025-12-07T12:23:44.536427Z","iopub.status.idle":"2025-12-07T12:23:44.545889Z","shell.execute_reply.started":"2025-12-07T12:23:44.536368Z","shell.execute_reply":"2025-12-07T12:23:44.544739Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# split с ratio=1\ntrain_d, val_d, test_d = make_split(1)\n\nhidden_dim = 64\nepochs = 60\n\narchs_lp = {\n    \"GCN\": GCNEncoder_simple,\n    \"GraphSAGE\": SAGEEncoder,\n    \"GIN\": GINEncoder,\n}\n\nresults_lp_arch = []\n\nfor name, enc_cls in archs_lp.items():\n    print(f\"\\n=== Training {name} encoder for LP ===\")\n    encoder = enc_cls(data.num_features, hidden_dim).to(device)\n    optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n\n    for epoch in range(epochs):\n        loss = train_lp_simple(encoder, train_d, optimizer)\n        if epoch % 20 == 0:\n            print(f\"{name} | Epoch {epoch} | Loss={loss:.4f}\")\n\n    val_auc, val_ap = eval_lp_simple(encoder, val_d)\n    test_auc, test_ap = eval_lp_simple(encoder, test_d)\n\n    results_lp_arch.append({\n        \"Encoder\": name,\n        \"Val AUC\": val_auc,\n        \"Val AP\": val_ap,\n        \"Test AUC\": test_auc,\n        \"Test AP\": test_ap\n    })\n\ndf_lp_arch = pd.DataFrame(results_lp_arch)\ndf_lp_arch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T12:24:57.925998Z","iopub.execute_input":"2025-12-07T12:24:57.926332Z","iopub.status.idle":"2025-12-07T12:25:08.070053Z","shell.execute_reply.started":"2025-12-07T12:24:57.926309Z","shell.execute_reply":"2025-12-07T12:25:08.068597Z"}},"outputs":[{"name":"stdout","text":"\n=== Training GCN encoder for LP ===\nGCN | Epoch 0 | Loss=0.6667\nGCN | Epoch 20 | Loss=0.4739\nGCN | Epoch 40 | Loss=0.3290\n\n=== Training GraphSAGE encoder for LP ===\nGraphSAGE | Epoch 0 | Loss=0.7107\nGraphSAGE | Epoch 20 | Loss=0.4645\nGraphSAGE | Epoch 40 | Loss=0.2931\n\n=== Training GIN encoder for LP ===\nGIN | Epoch 0 | Loss=0.7278\nGIN | Epoch 20 | Loss=0.5693\nGIN | Epoch 40 | Loss=0.4999\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"     Encoder   Val AUC    Val AP  Test AUC   Test AP\n0        GCN  0.840622  0.852552  0.852406  0.862299\n1  GraphSAGE  0.722079  0.657013  0.734435  0.698927\n2        GIN  0.726669  0.741995  0.788402  0.810218","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Encoder</th>\n      <th>Val AUC</th>\n      <th>Val AP</th>\n      <th>Test AUC</th>\n      <th>Test AP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GCN</td>\n      <td>0.840622</td>\n      <td>0.852552</td>\n      <td>0.852406</td>\n      <td>0.862299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GraphSAGE</td>\n      <td>0.722079</td>\n      <td>0.657013</td>\n      <td>0.734435</td>\n      <td>0.698927</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GIN</td>\n      <td>0.726669</td>\n      <td>0.741995</td>\n      <td>0.788402</td>\n      <td>0.810218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"### Вывод по пункту 2.4\n\nВ данном пункте сравнивались три архитектуры энкодера в задаче предсказания рёбер: GCN, GraphSAGE и GIN. Во всех случаях использовался одинаковый dot-product-декодер и одинаковое отношение положительных и отрицательных примеров (1:1), что обеспечивает корректное сравнение моделей.\n\nGCN-энкодер показывает наилучшие результаты по всем метрикам: `Val AUC = 0.841`, `Val AP = 0.853`, `Test AUC = 0.852` и `Test AP = 0.862`. Это указывает на то, что классическая графовая сверточная сеть хорошо захватывает структуру графа цитирований Cora и формирует эмбеддинги, пригодные для восстановления рёбер.\n\nGraphSAGE демонстрирует заметно более низкие показатели (`Val AUC = 0.722`, `Test AUC = 0.734`). Агрегация признаков соседей через усреднение в данном случае приводит к потере части тонкой структурной информации, что снижает качество предсказания рёбер по сравнению с GCN.\n\nGIN-энкодер по валидационным метрикам сопоставим с GraphSAGE (`Val AUC ≈ 0.727`), однако показывает более высокое качество на тестовой выборке (`Test AUC = 0.788`, `Test AP = 0.810`). Это согласуется с тем, что GIN-архитектура обладает большей теоретической выразительностью и лучше различает локальные подпоследовательности в графе, что полезно для задачи link prediction.\n\nВ сумме результаты показывают, что для рассматриваемой конфигурации и датасета Cora базовый GCN-энкодер остаётся наиболее эффективным решением, тогда как GIN выступает как более сложная, но перспективная альтернатива, а GraphSAGE в данном виде уступает им по качеству.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}