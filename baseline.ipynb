{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QR2k8loeyxY"
   },
   "source": [
    "установка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "urjj3lvfdpN0"
   },
   "outputs": [],
   "source": [
    "! pip install datasets docx2txt langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FbsOaaHkX5mD"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import re\n",
    "from docx import Document\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td30PulvcChp"
   },
   "source": [
    "## Инициализация клиента и моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "evvbEM21f7dN"
   },
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-TeK03KzPC8jTYJP7Pmf60w\",\n",
    "    base_url=\"https://api.vsellm.ru/v1\"\n",
    ")\n",
    "\n",
    "embed_model_name = 'openai/text-embedding-3-small'\n",
    "generative_model_name = \"openai/gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnVrSnlGfQY6"
   },
   "source": [
    "## Пример использования генеративных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIgQGB7maMFe"
   },
   "source": [
    "Генерация эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqzaebOFfwa6",
    "outputId": "b1d8bbe6-a2a5-4d83-ef77-80e2f730f104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Graph Neural Networks are powerful\",\n",
    "    \"GNNs are used in recommender systems\",\n",
    "    \"Transformers work well for NLP\"\n",
    "]\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=embed_model_name,\n",
    "    input=texts\n",
    ")\n",
    "\n",
    "embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "print(len(embeddings))          # количество текстов\n",
    "print(len(embeddings[0]))       # размерность эмбеддинга (3072)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-t9hg39aJnJ"
   },
   "source": [
    "Генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oM5Lfo-fX1ay",
    "outputId": "abed1f15-42d3-4a93-ab5f-ee1801dd2501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет! Как могу помочь?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=generative_model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Привет!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWwLBp4eb9Hz"
   },
   "source": [
    "## Baseline HACK2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXIg0YeRcIbP"
   },
   "source": [
    "## Загрузка базы знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlY7OiXlcEKo",
    "outputId": "0af2ebb6-99bf-492c-8803-ef2d48106a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка PDF: GNN_module1.pdf\n",
      "Загрузка PDF: GNN_module2.pdf\n",
      "Загрузка PDF: module3.pdf\n",
      "Загрузка PDF: module4.pdf\n",
      "Загрузка PDF: module5.pdf\n",
      "Загрузка PDF: module6.pdf\n",
      "Загрузка PDF: module7.pdf\n",
      "Загрузка PDF: module8.pdf\n",
      "Загрузка DOCX: Курс.docx\n",
      "\n",
      "Найдено файлов: 9\n",
      "Total chunks: 380\n"
     ]
    }
   ],
   "source": [
    "def load_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text(\"text\") + \"\\n\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "data_folder = Path(\"lectures\") \n",
    "\n",
    "texts = []\n",
    "for file in data_folder.glob(\"*\"):\n",
    "    if file.suffix == \".docx\":\n",
    "        print(f\"Загрузка DOCX: {file.name}\")\n",
    "        texts.append(load_docx(file))\n",
    "    elif file.suffix == \".pdf\":\n",
    "        print(f\"Загрузка PDF: {file.name}\")\n",
    "        texts.append(load_pdf(file))\n",
    "        \n",
    "print(f\"\\nНайдено файлов: {len(texts)}\")\n",
    "\n",
    "full_text = \"\\n\".join(texts)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = splitter.split_text(full_text)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPSGZB62cQB_"
   },
   "source": [
    "## Генерация эмбеддингов для чанков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qjAeQ5V2cQrg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [01:17<00:00,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги сгенерированы: (380, 1536)\n",
      "Пример: [-0.04010519 -0.04786523  0.00559865 -0.00976413  0.04092081]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# обновлено для работы не только с docx\n",
    "def embed_documents(texts):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), 50)):  # батчами по 50\n",
    "        batch = texts[i:i+50]\n",
    "        response = client.embeddings.create(\n",
    "            model=embed_model_name,\n",
    "            input=batch\n",
    "        )\n",
    "        embeddings.extend([item.embedding for item in response.data])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "chunk_embeddings = embed_documents(chunks)\n",
    "print(\"Эмбеддинги сгенерированы:\", chunk_embeddings.shape)\n",
    "print(\"Пример:\", chunk_embeddings[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlHLawKoeIHX"
   },
   "source": [
    "## Retrieval (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l9pBg4GacRqy"
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    query_emb = client.embeddings.create(\n",
    "        model=embed_model_name,\n",
    "        input=[query]\n",
    "    ).data[0].embedding\n",
    "\n",
    "    scores = [\n",
    "        cosine_sim(query_emb, emb)\n",
    "        for emb in chunk_embeddings\n",
    "    ]\n",
    "\n",
    "    top_idx = np.argsort(scores)[-k:][::-1]\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"text\": chunks[i],\n",
    "            \"score\": float(scores[i])\n",
    "        }\n",
    "        for i in top_idx\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Img6Ls0eWuj"
   },
   "source": [
    "## Сбор контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "r4QCrvqCeLnv"
   },
   "outputs": [],
   "source": [
    "def build_context(retrieved_chunks):\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"[score={c['score']:.3f}]\\n{c['text']}\"\n",
    "        for c in retrieved_chunks\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oxw19YVeaSb"
   },
   "source": [
    "## Генерация ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "E-LHLuu6eVy0"
   },
   "outputs": [],
   "source": [
    "def generate_answer(question, context):\n",
    "    response = client.chat.completions.create(\n",
    "        model=generative_model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"Ты ассистент, отвечающий на вопросы по курсу Graph Neural Networks. \"\n",
    "                    \"Используй только предоставленный контекст.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "Контекст:\n",
    "{context}\n",
    "\n",
    "Вопрос:\n",
    "{question}\n",
    "\n",
    "Дай краткий и точный ответ.\n",
    "\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SisXAziHeffN"
   },
   "source": [
    "## Финальная функция answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Fm786kixecKt"
   },
   "outputs": [],
   "source": [
    "def answer(question, k=5):\n",
    "    retrieved = retrieve(question, k)\n",
    "    context = build_context(retrieved)\n",
    "    answer_text = generate_answer(question, context)\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer_text,\n",
    "        \"retrieved_chunks\": retrieved\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DU9a04msehvU",
    "outputId": "6af082a0-927b-4877-ca51-a35ce62c3324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Neural Network (GNN) — это класс нейронных сетей для обработки данных, которые можно представить в виде графов.\n"
     ]
    }
   ],
   "source": [
    "result = answer(\"Что такое Graph Neural Network?\")\n",
    "\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:30<00:00,  1.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Что такое граф и как он формально задаётся?</td>\n",
       "      <td>Граф — это структура данных, описывающая объек...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие основные компоненты используются для опи...</td>\n",
       "      <td>Основные компоненты динамического графа: множе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В чём отличие snapshot-based и event-based дин...</td>\n",
       "      <td>Snapshot-based динамика представляет граф как ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Какие задачи решают динамические GNN?</td>\n",
       "      <td>Динамические GNN решают задачи: 1) временное п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Почему для динамических графов требуется памят...</td>\n",
       "      <td>Для динамических графов требуется память узлов...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0        Что такое граф и как он формально задаётся?   \n",
       "1  Какие основные компоненты используются для опи...   \n",
       "2  В чём отличие snapshot-based и event-based дин...   \n",
       "3              Какие задачи решают динамические GNN?   \n",
       "4  Почему для динамических графов требуется памят...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Граф — это структура данных, описывающая объек...  \n",
       "1  Основные компоненты динамического графа: множе...  \n",
       "2  Snapshot-based динамика представляет граф как ...  \n",
       "3  Динамические GNN решают задачи: 1) временное п...  \n",
       "4  Для динамических графов требуется память узлов...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_excel(\"QA_dataset.xlsx\")\n",
    "questions = qa_df[\"Question\"].dropna().tolist()\n",
    "answers = []\n",
    "\n",
    "for q in tqdm(questions):\n",
    "    res = answer(q, k=5)\n",
    "    answers.append(res[\"answer\"])\n",
    "\n",
    "qa_df[\"Answer\"] = answers\n",
    "qa_df.to_excel(\"QA_dataset_answered_baseline.xlsx\", index=False)\n",
    "\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP5GUkk8ghCW"
   },
   "source": [
    "#### Где можно вдохновиться: RAG From Scratch"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
